### CS224N:

1. Word2Vec: http://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf
  - reduced model complexity by simpler architecture >> train on more samples in around same time but get higher accuracy
2. Negative Sampling: Efficient Estimation of Word Representations in Vector Space :https://arxiv.org/pdf/1301.3781.pdf
3. Improving Word Representations Via Global Context And Multiple Word Prototypes (Huang et al, 2012)
4. http://nlp.stanford.edu/pubs/glove.pdf
5. Improving Distributional Similarity with Lessons Learned from Word Embeddings: http://www.aclweb.org/anthology/Q15-1016
6. Evaluation methods for unsupervised word embeddings: http://www.aclweb.org/anthology/D15-1036
7. A Latent Variable Model Approach to PMI-based Word Embeddings: http://aclweb.org/anthology/Q16-1028
8. Linear Algebraic Structure of Word Senses, with Applications to Polysemy: https://transacl.org/ojs/index.php/tacl/article/viewFile/1346/320
9. On the Dimensionality of Word Embedding : https://papers.nips.cc/paper/7368-on-the-dimensionality-of-word-embedding.pdf
10. fasttext


Random Thoughts:
1. LSA VS LDA - pros/cons
2. 
3. 
